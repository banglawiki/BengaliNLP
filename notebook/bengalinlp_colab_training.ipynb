{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banglawiki/bengalinlp/blob/bengalinlp_4_dev/notebook/bengalinlp_colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SQ0x9bh9QsL"
      },
      "source": [
        "# BengaliNLP\n",
        "\n",
        "BengaliNLP is a natural language processing toolkit for Bengali Language. This tool will help you to tokenize Bengali text, Embedding Bengali words, Bengali POS Tagging, Construct Neural Model for Bengali NLP purposes.\n",
        "\n",
        "Here we are prodiving training approach of different model using **BengaliNLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuT4uyIf5-Gy"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJN642aj5nVc",
        "outputId": "f51e370b-2244-4a67-a3d6-e63a0f2cb462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/requests-2.32.3-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/bengalinlp-2.0.0-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/ftfy-6.2.0-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/emoji-1.7.0-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/sklearn_crfsuite-0.3.6-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/dev/BengaliNLP/.venv/lib/python3.13/site-packages/tqdm-4.66.3-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement bengalinlp==1.0.0.dev1 (from versions: 1.0.0, 2.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for bengalinlp==1.0.0.dev1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install -U bengalinlp_toolkit\n",
        "!pip install bengalinlp==1.0.0.dev1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWy0qUdy6BY3"
      },
      "source": [
        "##  Download Bengali Wiki data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcwFE8le5yTF",
        "outputId": "73ed584d-b40f-4532-aa07-59cd48cac2c2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gdown'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgdown\u001b[39;00m\n\u001b[32m      2\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://drive.google.com/uc?id=1rQUQLsXg0TZnlrAgmNMkCXGDnYbjlLmM\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m output = \u001b[33m\"\u001b[39m\u001b[33mbn_wiki_data.txt.zip\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gdown'"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1rQUQLsXg0TZnlrAgmNMkCXGDnYbjlLmM\"\n",
        "output = \"bn_wiki_data.txt.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "!unzip bn_wiki_data.txt.zip\n",
        "!rm -rf bn_wiki_data.txt.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywTQFAeU6QEx"
      },
      "source": [
        "## Sample Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL96g8j16PWG",
        "outputId": "5c31e464-ac4e-4e07-aeae-369b981feb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing sample.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile sample.txt\n",
        "চলতি সপ্তাহের শেষে সর্বজনীন পেনশন কর্মসূচির উদ্বোধন হতে যাচ্ছে। প্রধানমন্ত্রীর কার্যালয় থেকে অর্থ মন্ত্রণালয়ে পাঠানো চিঠিতে বলা হয়েছে, প্রধানমন্ত্রী শেখ হাসিনা আগামী ১৭ আগস্ট বৃহস্পতিবার ভার্চ্যুয়াল পদ্ধতিতে এ কর্মসূচির উদ্বোধন করবেন।\n",
        "\n",
        "ওই দিন সকাল ১০টায় ঢাকায় গণভবন থেকে প্রধানমন্ত্রী পেনশন কর্মসূচির উদ্বোধন করবেন। অনুষ্ঠানে সংযুক্ত থাকবে গোপালগঞ্জ, বাগেরহাট, রংপুর জেলা ও সৌদি আরবের বাংলাদেশ দূতাবাস।\n",
        "এর আগে অর্থ বিভাগ সূত্র প্রথম আলোকে জানিয়েছিল, সমাজের বিভিন্ন শ্রেণি-পেশার মানুষের কথা বিবেচনায় নিয়ে সর্বজনীন পেনশন কর্মসূচি চালু করা হচ্ছে। আপাতত চার শ্রেণির জনগোষ্ঠীর জন্য চার ধরনের পেনশন কর্মসূচি চালু করা হচ্ছে। এগুলোর নাম হচ্ছে প্রগতি, সুরক্ষা, সমতা ও প্রবাসী।\n",
        "\n",
        "\n",
        "এর মধ্যে বেসরকারি খাতের চাকরিজীবীদের জন্য ‘প্রগতি’, স্বকর্মে নিয়োজিত ব্যক্তিদের জন্য ‘সুরক্ষা’, প্রবাসী বাংলাদেশিদের জন্য ‘প্রবাসী’ ও দেশের নিম্ন আয়ের জনগোষ্ঠীর জন্য ‘সমতা’ শীর্ষক কর্মসূচি চালু করা হবে।\n",
        "\n",
        "সর্বজনীন পেনশন কর্মসূচি এমনভাবে করা হচ্ছে, যাতে দেশের ১৮ থেকে ৫০ বছর বয়সী সব নাগরিকই এ ব্যবস্থার আওতায় আসতে পারেন এবং ৬০ বছর বয়স থেকে তাঁরা আজীবন পেনশন পাবেন। শুরুর দিকে চিন্তা না থাকলেও পরে ৫০ বছরের বেশি বয়সীদেরও পেনশন কর্মসূচির আওতায় রাখার সুযোগ তৈরি করা হয়েছে। তাঁরা টানা ১০ বছর চাঁদা দেওয়ার পর পেনশন সুবিধা পাবেন।\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350KPo4D6Z4o"
      },
      "source": [
        "## Training\n",
        "\n",
        "Here we present `bengali sentencepiece`, `bengali word2vec`, `bengali fasttext` training on `bengali wikipedia data`\n",
        "\n",
        "Training time will depend on data size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_wHJFOW6dlo"
      },
      "source": [
        "### Training Bengali Sentencepice Model\n",
        "\n",
        "After successfully compiling the below code will produce two file:\n",
        "\n",
        "* `wiki_sp.model`\n",
        "* `wiki_sp.vecab`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l7DUWI66MD4",
        "outputId": "89201111-80d5-42d0-bdc8-d31ab4657229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.model and model.vocab is saved on your current directory\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import SentencepieceTrainer\n",
        "\n",
        "data = \"sample.txt\"\n",
        "vocab_size = 100\n",
        "model_prefix = \"model\"\n",
        "\n",
        "trainer = SentencepieceTrainer(\n",
        "   data=data,\n",
        "   vocab_size=vocab_size,\n",
        "   model_prefix=model_prefix\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-k4Dszo61v2"
      },
      "source": [
        "### Training Bengali Word2Vec Model\n",
        "\n",
        "After successfully compiling it will produce three file.\n",
        "\n",
        "* `wiki_word2vec.model`\n",
        "* `wiki_word2vec.vector`\n",
        "* `wiki_word2vec.model.trainables.syn1neg.npy`\n",
        "* `wiki_word2vec..model.wv.vectors.npy`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OphHV5Yp60KW",
        "outputId": "7af25b9a-b53d-4f09-9e8d-02e8e70b82da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training started.......\n",
            "please wait.....it will take time according to your data size and computation capability\n",
            "train completed successfully\n",
            "trianing loss: 44.43490219116211\n",
            "model and vector saving...\n",
            "model and vector saved as test_model.model and test_vector.vector\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import Word2VecTraining\n",
        "\n",
        "trainer = Word2VecTraining()\n",
        "\n",
        "data_file = \"sample.txt\" # or you can pass custom sentence tokens as list of list\n",
        "model_name = \"test_model.model\"\n",
        "vector_name = \"test_vector.vector\"\n",
        "trainer.train(data_file, model_name, vector_name, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdMRUO0jzV8v"
      },
      "source": [
        "### Pre-training or resume Bengali word2vec training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1aTn9cnzV8v",
        "outputId": "ab71f451-e873-4867-8a9c-f0800a034d26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model loading ....\n",
            "vocab building with new sentences\n",
            "pre-training started.......\n",
            "please wait.....it will take time according to your data size and computation capability\n",
            "pre-train completed successfully\n",
            "pre-trianing loss: 0.0\n",
            "model and vector saving...\n",
            "model and vector saved as test_model.model and test_vector.vector\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import Word2VecTraining\n",
        "\n",
        "trainer = Word2VecTraining()\n",
        "\n",
        "trained_model_path = \"test_model.model\"\n",
        "data_file = \"sample.txt\"\n",
        "model_name = \"test_model.model\"\n",
        "vector_name = \"test_vector.vector\"\n",
        "trainer.pretrain(trained_model_path, data_file, model_name, vector_name, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAMgr4WT8x2a"
      },
      "source": [
        "### Training Bengali Fasttext Model\n",
        "First of all install `fasttext` using `pip install fasttext` and restart runtime.\n",
        "\n",
        "After successfully training it will produce:\n",
        "* `wiki_fasttext.bin`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXptOhxg4s6r",
        "outputId": "8ef5c7cf-947a-49db-8518-378457cd55fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199770 sha256=c71df6599369022ad45445efe631c0f692a67fa2b1e78ca6ca3c0d04d4ca944c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F67Yzdu08xBd",
        "outputId": "48c61612-9c72-4995-a5ce-3e3c7acfd01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training started.....\n",
            "training done! saving as saved_model.bin\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp.embedding.fasttext import FasttextTrainer\n",
        "\n",
        "trainer = FasttextTrainer()\n",
        "\n",
        "data = \"sample.txt\"\n",
        "model_name = \"saved_model.bin\"\n",
        "epoch = 5\n",
        "trainer.train(data, model_name, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_D6o84iz9le"
      },
      "source": [
        "## Training Bengali Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yNxSzNq0Al1",
        "outputId": "8ed3238e-fed4-44e8-e986-f8c344f4d48e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00, 454.77it/s]\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import BengaliDoc2vecTrainer\n",
        "\n",
        "trainer = BengaliDoc2vecTrainer()\n",
        "\n",
        "text_files = \"./\"\n",
        "checkpoint_path = \"logs\"\n",
        "\n",
        "trainer.train(\n",
        "  text_files,\n",
        "  checkpoint_path=checkpoint_path,\n",
        "  vector_size=100,\n",
        "  min_count=2,\n",
        "  epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtsLVmOs9lgG"
      },
      "source": [
        "### Training Bengali POS TAGGING CRF model\n",
        "\n",
        "After successfully training it will produce a trained model with accuracy on evaluation data:\n",
        "\n",
        "* `pos_model.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUKhbkaBE-CV",
        "outputId": "378b73d1-dc4d-4260-f0a4-39d9b2da0e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "Training Started........\n",
            "It will take time according to your dataset size...\n",
            "Training Finished!\n",
            "Evaluating with Test Data...\n",
            "Accuracy is: \n",
            "1.0\n",
            "F1 Score(micro) is: \n",
            "1.0\n",
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import CRFTaggerTrainer\n",
        "\n",
        "trainer = CRFTaggerTrainer()\n",
        "\n",
        "model_name = \"pos_model.pkl\"\n",
        "train_data = [[('রপ্তানি', 'JJ'), ('দ্রব্য', 'NC'), ('-', 'PU'), ('তাজা',  'JJ'), ('ও', 'CCD'), ('শুকনা', 'JJ'), ('ফল', 'NC'), (',', 'PU'), ('আফিম', 'NC'), (',', 'PU'), ('পশুচর্ম', 'NC'), ('ও', 'CCD'), ('পশম', 'NC'), ('এবং', 'CCD'),('কার্পেট', 'NC'), ('৷', 'PU')], [('মাটি', 'NC'), ('থেকে', 'PP'), ('বড়জোর', 'JQ'), ('চার', 'JQ'), ('পাঁচ', 'JQ'), ('ফুট', 'CCL'), ('উঁচু', 'JJ'), ('হবে', 'VM'), ('৷', 'PU')]]\n",
        "\n",
        "test_data = [[('রপ্তানি', 'JJ'), ('দ্রব্য', 'NC'), ('-', 'PU'), ('তাজা', 'JJ'), ('ও', 'CCD'), ('শুকনা', 'JJ'), ('ফল', 'NC'), (',', 'PU'), ('আফিম', 'NC'), (',', 'PU'), ('পশুচর্ম', 'NC'), ('ও', 'CCD'), ('পশম', 'NC'), ('এবং', 'CCD'),('কার্পেট', 'NC'), ('৷', 'PU')], [('মাটি', 'NC'), ('থেকে', 'PP'), ('বড়জোর', 'JQ'), ('চার', 'JQ'), ('পাঁচ', 'JQ'), ('ফুট', 'CCL'), ('উঁচু', 'JJ'), ('হবে', 'VM'), ('৷', 'PU')]]\n",
        "\n",
        "trainer.train(model_name, train_data, test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPB7SBrKuSna"
      },
      "source": [
        "## Training Bengali NER model\n",
        "After successfully training it will produce a trained model with accuracy on evaluation data:\n",
        "\n",
        "* `ner_model.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of_1lkdW917n",
        "outputId": "f877b62a-b568-4d45-81ae-b4e770a95ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "Training Started........\n",
            "It will take time according to your dataset size...\n",
            "Training Finished!\n",
            "Evaluating with Test Data...\n",
            "Accuracy is: \n",
            "1.0\n",
            "F1 Score(micro) is: \n",
            "1.0\n",
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "from bengalinlp import CRFTaggerTrainer\n",
        "\n",
        "trainer = CRFTaggerTrainer()\n",
        "\n",
        "model_name = \"ner_model.pkl\"\n",
        "train_data = [[('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')]]\n",
        "\n",
        "test_data = [[('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')]]\n",
        "\n",
        "trainer.train(model_name, train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVrYxT5DulwP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "bengalinlp_colab_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
