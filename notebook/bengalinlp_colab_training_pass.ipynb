{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bengalinlp_colab_training.ipynb",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banglawiki/BengaliNLP/blob/main/notebook/bengalinlp_colab_training_pass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BengaliNLP\n",
        "\n",
        "BengaliNLP is a natural language processing toolkit for Bengali Language. This tool will help you to tokenize Bengali text, Embedding Bengali words, Bengali POS Tagging, Construct Neural Model for Bengali NLP purposes.\n",
        "\n",
        "Here we are prodiving training approach of different model using **BengaliNLP**"
      ],
      "metadata": {
        "id": "0SQ0x9bh9QsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "MuT4uyIf5-Gy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "!pip install bengalinlp"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bengalinlp in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (0.2.0)\n",
            "Requirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (1.26.4)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (1.10.1)\n",
            "Requirement already satisfied: sklearn-crfsuite==0.3.6 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (0.3.6)\n",
            "Requirement already satisfied: tqdm==4.66.3 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (4.66.3)\n",
            "Requirement already satisfied: ftfy==6.2.0 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (6.2.0)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bengalinlp) (2.32.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.2.0->bengalinlp) (0.2.13)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.2->bengalinlp) (7.0.4)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bengalinlp) (0.9.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bengalinlp) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bengalinlp) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bengalinlp) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bengalinlp) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bengalinlp) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bengalinlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bengalinlp) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bengalinlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bengalinlp) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim==4.3.2->bengalinlp) (1.16.0)\n"
          ]
        }
      ],
      "metadata": {
        "id": "KJN642aj5nVc",
        "outputId": "80e7916a-d85e-4b54-919f-cf3340dfdbca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Download Bengali Wiki data"
      ],
      "metadata": {
        "id": "IWy0qUdy6BY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1rQUQLsXg0TZnlrAgmNMkCXGDnYbjlLmM\"\n",
        "output = \"bn_wiki_data.txt.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "!unzip bn_wiki_data.txt.zip\n",
        "!rm -rf bn_wiki_data.txt.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rQUQLsXg0TZnlrAgmNMkCXGDnYbjlLmM\n",
            "From (redirected): https://drive.google.com/uc?id=1rQUQLsXg0TZnlrAgmNMkCXGDnYbjlLmM&confirm=t&uuid=14c332e7-be8b-43e7-ac51-2baf02457747\n",
            "To: /content/bn_wiki_data.txt.zip\n",
            "100%|██████████| 69.2M/69.2M [00:00<00:00, 200MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bn_wiki_data.txt.zip\n",
            "replace bn_wiki_data.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "metadata": {
        "id": "AcwFE8le5yTF",
        "outputId": "5559b333-a9b9-4610-daac-6aa8e25ac784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Text Data"
      ],
      "metadata": {
        "id": "ywTQFAeU6QEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample.txt\n",
        "চলতি সপ্তাহের শেষে সর্বজনীন পেনশন কর্মসূচির উদ্বোধন হতে যাচ্ছে। প্রধানমন্ত্রীর কার্যালয় থেকে অর্থ মন্ত্রণালয়ে পাঠানো চিঠিতে বলা হয়েছে, প্রধানমন্ত্রী শেখ হাসিনা আগামী ১৭ আগস্ট বৃহস্পতিবার ভার্চ্যুয়াল পদ্ধতিতে এ কর্মসূচির উদ্বোধন করবেন।\n",
        "\n",
        "ওই দিন সকাল ১০টায় ঢাকায় গণভবন থেকে প্রধানমন্ত্রী পেনশন কর্মসূচির উদ্বোধন করবেন। অনুষ্ঠানে সংযুক্ত থাকবে গোপালগঞ্জ, বাগেরহাট, রংপুর জেলা ও সৌদি আরবের বাংলাদেশ দূতাবাস।\n",
        "এর আগে অর্থ বিভাগ সূত্র প্রথম আলোকে জানিয়েছিল, সমাজের বিভিন্ন শ্রেণি-পেশার মানুষের কথা বিবেচনায় নিয়ে সর্বজনীন পেনশন কর্মসূচি চালু করা হচ্ছে। আপাতত চার শ্রেণির জনগোষ্ঠীর জন্য চার ধরনের পেনশন কর্মসূচি চালু করা হচ্ছে। এগুলোর নাম হচ্ছে প্রগতি, সুরক্ষা, সমতা ও প্রবাসী।\n",
        "\n",
        "\n",
        "এর মধ্যে বেসরকারি খাতের চাকরিজীবীদের জন্য ‘প্রগতি’, স্বকর্মে নিয়োজিত ব্যক্তিদের জন্য ‘সুরক্ষা’, প্রবাসী বাংলাদেশিদের জন্য ‘প্রবাসী’ ও দেশের নিম্ন আয়ের জনগোষ্ঠীর জন্য ‘সমতা’ শীর্ষক কর্মসূচি চালু করা হবে।\n",
        "\n",
        "সর্বজনীন পেনশন কর্মসূচি এমনভাবে করা হচ্ছে, যাতে দেশের ১৮ থেকে ৫০ বছর বয়সী সব নাগরিকই এ ব্যবস্থার আওতায় আসতে পারেন এবং ৬০ বছর বয়স থেকে তাঁরা আজীবন পেনশন পাবেন। শুরুর দিকে চিন্তা না থাকলেও পরে ৫০ বছরের বেশি বয়সীদেরও পেনশন কর্মসূচির আওতায় রাখার সুযোগ তৈরি করা হয়েছে। তাঁরা টানা ১০ বছর চাঁদা দেওয়ার পর পেনশন সুবিধা পাবেন।\n",
        "\n"
      ],
      "metadata": {
        "id": "sL96g8j16PWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Here we present `bengali sentencepiece`, `bengali word2vec`, `bengali fasttext` training on `bengali wikipedia data`\n",
        "\n",
        "Training time will depend on data size."
      ],
      "metadata": {
        "id": "350KPo4D6Z4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Bengali Sentencepice Model\n",
        "\n",
        "After successfully compiling the below code will produce two file:\n",
        "\n",
        "* `wiki_sp.model`\n",
        "* `wiki_sp.vecab`"
      ],
      "metadata": {
        "id": "I_wHJFOW6dlo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from bengalinlp import SentencepieceTrainer\n",
        "\n",
        "data = \"sample.txt\"\n",
        "vocab_size = 100\n",
        "model_prefix = \"model\"\n",
        "\n",
        "trainer = SentencepieceTrainer(\n",
        "   data=data,\n",
        "   vocab_size=vocab_size,\n",
        "   model_prefix=model_prefix\n",
        ")\n",
        "trainer.train()"
      ],
      "outputs": [],
      "metadata": {
        "id": "8l7DUWI66MD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Bengali Word2Vec Model\n",
        "\n",
        "After successfully compiling it will produce three file.\n",
        "\n",
        "* `wiki_word2vec.model`\n",
        "* `wiki_word2vec.vector`\n",
        "* `wiki_word2vec.model.trainables.syn1neg.npy`\n",
        "* `wiki_word2vec..model.wv.vectors.npy`\n"
      ],
      "metadata": {
        "id": "k-k4Dszo61v2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import nltk\n",
        "# Download the 'punkt' resource for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Your training code\n",
        "model_name = \"test_model.model\"\n",
        "vector_name = \"test_vector.vector\"\n",
        "trainer.train(data_file, model_name, vector_name, epochs=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OphHV5Yp60KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-training or resume Bengali word2vec training"
      ],
      "metadata": {
        "id": "wdMRUO0jzV8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from bengalinlp import Word2VecTraining\n",
        "\n",
        "trainer = Word2VecTraining()\n",
        "\n",
        "trained_model_path = \"test_model.model\"\n",
        "data_file = \"sample.txt\"\n",
        "model_name = \"test_model.model\"\n",
        "vector_name = \"test_vector.vector\"\n",
        "trainer.pretrain(trained_model_path, data_file, model_name, vector_name, epochs=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i1aTn9cnzV8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Bengali Fasttext Model\n",
        "First of all install `fasttext` using `pip install fasttext` and restart runtime.\n",
        "\n",
        "After successfully training it will produce:\n",
        "* `wiki_fasttext.bin`"
      ],
      "metadata": {
        "id": "TAMgr4WT8x2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install fasttext"
      ],
      "outputs": [],
      "metadata": {
        "id": "JXptOhxg4s6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from bengalinlp.embedding.fasttext import FasttextTrainer\n",
        "\n",
        "trainer = FasttextTrainer()\n",
        "\n",
        "data = \"sample.txt\"\n",
        "model_name = \"saved_model.bin\"\n",
        "epoch = 5\n",
        "trainer.train(data, model_name, epoch)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F67Yzdu08xBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Bengali Doc2Vec"
      ],
      "metadata": {
        "id": "C_D6o84iz9le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bengalinlp import BengaliDoc2vecTrainer\n",
        "\n",
        "trainer = BengaliDoc2vecTrainer()\n",
        "\n",
        "text_files = \"./\"\n",
        "checkpoint_path = \"logs\"\n",
        "\n",
        "trainer.train(\n",
        "  text_files,\n",
        "  checkpoint_path=checkpoint_path,\n",
        "  vector_size=100,\n",
        "  min_count=2,\n",
        "  epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "5yNxSzNq0Al1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Bengali POS TAGGING CRF model\n",
        "\n",
        "After successfully training it will produce a trained model with accuracy on evaluation data:\n",
        "\n",
        "* `pos_model.pkl`"
      ],
      "metadata": {
        "id": "ZtsLVmOs9lgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from bengalinlp import CRFTaggerTrainer\n",
        "\n",
        "trainer = CRFTaggerTrainer()\n",
        "\n",
        "model_name = \"pos_model.pkl\"\n",
        "train_data = [[('রপ্তানি', 'JJ'), ('দ্রব্য', 'NC'), ('-', 'PU'), ('তাজা',  'JJ'), ('ও', 'CCD'), ('শুকনা', 'JJ'), ('ফল', 'NC'), (',', 'PU'), ('আফিম', 'NC'), (',', 'PU'), ('পশুচর্ম', 'NC'), ('ও', 'CCD'), ('পশম', 'NC'), ('এবং', 'CCD'),('কার্পেট', 'NC'), ('৷', 'PU')], [('মাটি', 'NC'), ('থেকে', 'PP'), ('বড়জোর', 'JQ'), ('চার', 'JQ'), ('পাঁচ', 'JQ'), ('ফুট', 'CCL'), ('উঁচু', 'JJ'), ('হবে', 'VM'), ('৷', 'PU')]]\n",
        "\n",
        "test_data = [[('রপ্তানি', 'JJ'), ('দ্রব্য', 'NC'), ('-', 'PU'), ('তাজা', 'JJ'), ('ও', 'CCD'), ('শুকনা', 'JJ'), ('ফল', 'NC'), (',', 'PU'), ('আফিম', 'NC'), (',', 'PU'), ('পশুচর্ম', 'NC'), ('ও', 'CCD'), ('পশম', 'NC'), ('এবং', 'CCD'),('কার্পেট', 'NC'), ('৷', 'PU')], [('মাটি', 'NC'), ('থেকে', 'PP'), ('বড়জোর', 'JQ'), ('চার', 'JQ'), ('পাঁচ', 'JQ'), ('ফুট', 'CCL'), ('উঁচু', 'JJ'), ('হবে', 'VM'), ('৷', 'PU')]]\n",
        "\n",
        "trainer.train(model_name, train_data, test_data)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "VUKhbkaBE-CV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FLtsySMSNkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Bengali NER model\n",
        "After successfully training it will produce a trained model with accuracy on evaluation data:\n",
        "\n",
        "* `ner_model.pkl`"
      ],
      "metadata": {
        "id": "dPB7SBrKuSna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from bengalinlp import CRFTaggerTrainer\n",
        "\n",
        "trainer = CRFTaggerTrainer()\n",
        "\n",
        "model_name = \"ner_model.pkl\"\n",
        "train_data = [[('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')]]\n",
        "\n",
        "test_data = [[('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')], [('ত্রাণ', 'O'),('ও', 'O'),('সমাজকল্যাণ', 'O'),('সম্পাদক', 'S-PER'),('সুজিত', 'B-PER'),('রায়', 'I-PER'),('নন্দী', 'E-PER'),('প্রমুখ', 'O'),('সংবাদ', 'O'),('সম্মেলনে', 'O'),('উপস্থিত', 'O'),('ছিলেন', 'O')]]\n",
        "\n",
        "trainer.train(model_name, train_data, test_data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "of_1lkdW917n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "qVrYxT5DulwP"
      }
    }
  ]
}